# âœˆï¸ Flight Delay Predictor

---

## ğŸ“Œ Contexte

Les retards de vols reprÃ©sentent un enjeu majeur pour les compagnies aÃ©riennes, les aÃ©roports et les passagers. En 2019, **19â€¯% des vols aux Ã‰tats-Unis** ont Ã©tÃ© retardÃ©s, causant prÃ¨s de **28 milliards de dollars** de pertes Ã©conomiques (source : *Bureau of Transportation Statistics*). Ces retards sont dus Ã  de nombreux facteurs : conditions mÃ©tÃ©o, trafic aÃ©rien, problÃ¨mes techniques, etc.

Ce projet a pour objectif de **dÃ©velopper un modÃ¨le de machine learning** capable de prÃ©dire si un vol sera **retardÃ© de plus de 15 minutes Ã  lâ€™arrivÃ©e**, dans une logique dâ€™**industrialisation complÃ¨te** (ETL, API, monitoring, MLOps).

---

## ğŸ¯ Objectifs

- PrÃ©dire de maniÃ¨re **binaire** si un vol sera **retardÃ© (>15 min)** Ã  l'arrivÃ©e.
- Industrialiser le processus de bout en bout :
  - Pipeline ETL automatisÃ©
  - Stockage et historisation des donnÃ©es
  - EntraÃ®nement, suivi et versioning du modÃ¨le (MLflow)
  - DÃ©ploiement via une API REST (FastAPI)
  - Interface utilisateur (Streamlit)
  - Monitoring systÃ¨me (Grafana / Prometheus)
- Respect des contraintes **Ã©thiques**, **RGPD** et de **scalabilitÃ©**.

---

## ğŸ§± Architecture du projet


```
.
â”œâ”€â”€ alembic.ini                                # Alembic configuration file for database migrations
â”œâ”€â”€ api                                        # FastAPI backend for prediction service
â”‚Â Â  â”œâ”€â”€ Dockerfile                             # Docker configuration for API
â”‚Â Â  â”œâ”€â”€ endpoints                              # API route handlers
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ health.py                          # Health check endpoint
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ predict.py                         # Prediction endpoint using trained model
â”‚Â Â  â”œâ”€â”€ main.py                                # FastAPI app entrypoint
â”‚Â Â  â”œâ”€â”€ models                                 # Pydantic schemas for request/response models
â”‚Â Â  â”‚Â Â  â””â”€â”€ schemas.py                         # Request/response data schemas
â”‚Â Â  â”œâ”€â”€ requirements.txt                       # Python dependencies for API service
â”‚Â Â  â””â”€â”€ services                               # Core logic used by endpoints
â”‚Â Â      â””â”€â”€ prediction_service.py              # Model loading and prediction logic
â”œâ”€â”€ app                                        # Streamlit application for UI
â”‚Â Â  â”œâ”€â”€ Dockerfile                             # Docker configuration for Streamlit app
â”‚Â Â  â”œâ”€â”€ main.py                                # Streamlit app entrypoint
â”‚Â Â  â””â”€â”€ requirements.txt                       # Python dependencies for Streamlit app
â”œâ”€â”€ assets                                     # Generated performance plots and diagrams
â”‚Â Â  â”œâ”€â”€ *.png                                  # Visual assets (MLflow, Docker, LightGBM, etc.)
â”œâ”€â”€ data                                       # Raw and processed datasets
â”‚Â Â  â”œâ”€â”€ processed
â”‚Â Â  â”‚Â Â  â””â”€â”€ cleaned_data.csv                   # Cleaned and preprocessed dataset
â”‚Â Â  â””â”€â”€ raw                                    # Original CSV data (monthly)
â”‚Â Â      â”œâ”€â”€ 2016_MM.csv                        # Raw flight data from Jan to Dec
â”œâ”€â”€ database                                   # Database models and migration logic
â”‚Â Â  â”œâ”€â”€ base.py                                # SQLAlchemy base class
â”‚Â Â  â”œâ”€â”€ __init__.py                            # Makes "database" a Python package
â”‚Â Â  â”œâ”€â”€ migrations                             # Alembic migration scripts
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ env.py                             # Alembic environment setup
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ versions/*.py                      # Auto-generated migration scripts
â”‚Â Â  â”œâ”€â”€ models                                 # SQLAlchemy models for each table
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ airline.py                         # Airline table definition
â”‚Â Â  â”‚Â Â  â”œâ”€â”€ airports.py                        # Airports table definition
â”‚Â Â  â”‚Â Â  â””â”€â”€ flight.py                          # Flights table definition
â”‚Â Â  â”œâ”€â”€ schemas                                # Pydantic schemas for DB entities
â”‚Â Â  â”‚Â Â  â””â”€â”€ flight.py                          # Flight-specific schema
â”‚Â Â  â””â”€â”€ services                               # Data access layer logic
â”‚Â Â      â””â”€â”€ flight_service.py                  # Queries for the flights dataset
â”œâ”€â”€ docker-compose.yml                         # Orchestration file to run containers together
â”œâ”€â”€ dump                                       # Contains local SQLite database dump
â”‚Â Â  â””â”€â”€ flights.db                             # SQLite database file
â”œâ”€â”€ exploratory_data_analysis.ipynb            # Jupyter notebook for exploratory data analysis
â”œâ”€â”€ journal-de-bord.ipynb                      # Project logbook / research notebook
â”œâ”€â”€ Makefile                                   # Automation commands (build, test, etc.)
â”œâ”€â”€ ml                                         # Machine learning logic
â”‚Â Â  â”œâ”€â”€ evaluation
â”‚Â Â  â”‚Â Â  â””â”€â”€ evaluate.py                        # Model evaluation script (metrics, plots)
â”‚Â Â  â”œâ”€â”€ models_artifact                        # Pickled models and preprocessors
â”‚Â Â  â”‚Â Â  â””â”€â”€ *.pkl                              # Serialized sklearn/LGBM models and preprocessors
â”‚Â Â  â””â”€â”€ training                               # Model training and preprocessing logic
â”‚Â Â      â”œâ”€â”€ models.py                          # Model definitions and training logic
â”‚Â Â      â”œâ”€â”€ preprocessing.py                   # Data preprocessing steps (encoders, pipelines)
â”‚Â Â      â””â”€â”€ train_model.py                     # Full training script with MLflow/Optuna
â”œâ”€â”€ mlruns                                     # MLflow tracking folder (runs, metrics, models)
â”‚Â Â  â””â”€â”€ <experiment_id>/<run_id>               # Contains metrics, parameters, models for each run
â”œâ”€â”€ monitoring                                 # Observability setup
â”‚Â Â  â”œâ”€â”€ grafana                                # Grafana dashboards and config
â”‚Â Â  â””â”€â”€ prometheus                             # Prometheus scraping config
â”œâ”€â”€ README.md                                  # Project overview and documentation
â”œâ”€â”€ requirements.txt                           # Project-wide dependencies
â”œâ”€â”€ scripts                                    # One-off or utility scripts
â”‚Â Â  â””â”€â”€ clear_and_populate_db.py               # Initialize and populate the database
â””â”€â”€ tests                                      # Unit and integration tests
    â””â”€â”€ test_flight_service.py                 # Tests for the flight service logic
```
---

## âš™ï¸ Stack technique

- **Python 3.10+**
- **Pandas**, **Scikit-learn**, **LightGBM**
- **MLflow** pour le suivi des expÃ©rimentations
- **Optuna** pour lâ€™optimisation des hyperparamÃ¨tres
- **FastAPI** pour lâ€™API de prÃ©diction
- **Streamlit** pour lâ€™interface utilisateur
- **SQLite / PostgreSQL** via **SQLAlchemy** et **Alembic**
- **Docker** & **Docker Compose** pour la conteneurisation
- **Grafana + Prometheus** pour le monitoring des services

---

## ğŸŒ Environnement virtuel

**Linux / macOS**
```bash
python3 -m venv .venv
source .venv/bin/activate
```

**Windows**
```cmd
python -m venv .venv
.venv\Scripts\activate
```

---

## ğŸš€ Lancement du projet

### 1. Cloner le dÃ©pÃ´t

```bash
git clone https://github.com/ThomasHtn/flight-delay-predictor.git
cd flight-delay-predictor
```

### 2. Lancer avec Docker

```bash
docker-compose up --build
```

Cela dÃ©marre :
- Lâ€™API (FastAPI) sur http://0.0.0.0:8000/docs
- Lâ€™interface utilisateur (Streamlit) sur http://0.0.0.0:8501
- Le monitoring (Grafana) sur http://0.0.0.0:3000

---

## ğŸ“Š Monitoring

Lancer Prometheus & Grafana :

```bash
docker-compose up -d
```

- **Prometheus** : http://0.0.0.0:9090  
- **Grafana** : http://0.0.0.0:3000  

---

## ğŸ§ª Lancer les tests

```bash
make test
```

Les tests sont situÃ©s dans le dossier `tests/`. Ils sont Ã©galement exÃ©cutÃ©s automatiquement Ã  chaque push sur la branche `main` via **GitHub Actions**.

---

## ğŸ§¬ EntraÃ®ner les modÃ¨les

```bash
make train
```

Cela entraÃ®ne trois modÃ¨les :
- `RandomForest`
- `LogisticRegression`
- `LightGBM`

Les modÃ¨les sont enregistrÃ©s dans :
- `ml/models_artifact/`
- et suivis dans lâ€™interface MLflow : http://localhost:5000

---

## ğŸ“ˆ Ã‰valuation des performances

```bash
make evaluate
```

Par dÃ©faut, cela Ã©value `lightgbm_model.pkl` et gÃ©nÃ¨re une **matrice de confusion** enregistrÃ©e dans `assets/`.

---

## ğŸ§ª FastAPI (API REST)

Lancer lâ€™API manuellement :

```bash
uvicorn api.main:app --reload
```

Ou via Makefile :

```bash
make start-api
```

---

## ğŸ›ï¸ Streamlit (interface utilisateur)

Lancer lâ€™interface manuellement :

```bash
streamlit run app/main.py
```

Ou via Makefile :

```bash
make start-app
```

---

## âš—ï¸ Alembic (migrations)

CrÃ©er une nouvelle migration :

```bash
alembic revision --autogenerate -m "nom de la migration"
```

Appliquer la migration :

```bash
alembic upgrade head
```

Remplir la base de donnÃ©es :

```bash
make clear-and-populate-db
```

Cela nettoie les CSV du dossier `data/raw/` et les insÃ¨re dans la base de donnÃ©es SQLite.

---

## ğŸ“¦ MLflow

Lancer lâ€™interface MLflow :

```bash
mlflow ui
```

Interface : [http://localhost:5000](http://localhost:5000)

---

## âš™ï¸ GitHub Actions

Des pipelines CI/CD sont configurÃ©s :

- `test.yml` : exÃ©cute les tests Pytest
- `integration-check.yml` : vÃ©rifie que les conteneurs dÃ©marrent correctement
- `dockerhub.yml` : build et push automatique sur DockerHub

--- 

## ğŸ–¼ï¸ ApperÃ§u de l'application

**Streamlit**
![Streamlit](/assets/streamlit.png)

**Api de prediction**
![Api](/assets/api.png)

**Mlflow**
![Mlflow](/assets/mlflow.png)
![Mlflow](/assets/mlflow-details.png)
![Mlflow](/assets/mlflow-exploration.png)

**Lightgmb matrice de confusion**
![Lightgmb](/assets/lightgbm_confusion_matrix.png)

**Grafana**
![Grafana](/assets/grafana.png)

**Github actions**
![Actions](/assets/github-action.png)

**Docker hub**
![Docker](/assets/docker-hub.png)

