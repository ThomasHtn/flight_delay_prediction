# âœˆï¸ Flight Delay Predictor

--- 

## ğŸ“Œ Contexte

Les retards de vols reprÃ©sentent un enjeu majeur pour les compagnies aÃ©riennes, les aÃ©roports et les passagers. En 2019, 19â€¯% des vols aux Ã‰tats-Unis ont Ã©tÃ© retardÃ©s, engendrant prÃ¨s de **28 milliards de dollars** de pertes Ã©conomiques (source : *Bureau of Transportation Statistics*). Ces retards sont dus Ã  de nombreux facteurs : conditions mÃ©tÃ©o, trafic aÃ©rien, problÃ¨mes techniques, etc.

Ce projet vise Ã  **dÃ©velopper un modÃ¨le de machine learning** capable de prÃ©dire si un vol sera **retardÃ© de plus de 15 minutes Ã  lâ€™arrivÃ©e**. Ce modÃ¨le sâ€™inscrit dans une dÃ©marche dâ€™industrialisation complÃ¨te (ETL, monitoring, API, gestion des modÃ¨les).

*ETL = Extract, Transform, Load (en franÃ§ais : Extraire, Transformer, Charger)* *

---

## ğŸ¯ Objectifs

- PrÃ©dire de maniÃ¨re binaire si un vol sera **retardÃ© (>15 min)** Ã  l'arrivÃ©e.
- Industrialiser le processus complet :
  - Pipeline ETL automatisÃ©
  - Stockage et historisation des donnÃ©es
  - EntraÃ®nement et suivi du modÃ¨le (MLflow)
  - DÃ©ploiement via une API (FastAPI)
  - Interface utilisateur (Streamlit)
- Respect des contraintes **Ã©thiques**, **RGPD** et **scalabilitÃ©** de l'infrastructure.

--- 

## ğŸ§± Architecture du projet

```
.
â”‚
â”œâ”€â”€ api/                   # API FastAPI pour servir les prÃ©dictions
â”œâ”€â”€ app/                   # Application Streamlit
â”œâ”€â”€ database/
â”‚   â”œâ”€â”€ models/            # DÃ©finition des tables SQLAlchemy
â”‚   â”œâ”€â”€ schemas/           # SchÃ©mas Pydantic
â”‚   â””â”€â”€ migrations/        # Scripts Alembic pour la gestion du schÃ©ma
â”œâ”€â”€ etl/                   # Pipelines de traitement et ingestion des donnÃ©es
â”œâ”€â”€ ml/
â”‚   â”œâ”€â”€ training/          # Scripts d'entraÃ®nement
â”‚   â”œâ”€â”€ prediction/        # Chargement du modÃ¨le et prÃ©dictions
â”‚   â””â”€â”€ evaluation/        # Ã‰valuation et suivi des performances
â”œâ”€â”€ mlruns/                # Dossiers MLflow pour le tracking des expÃ©riences
â”œâ”€â”€ notebooks/             # Analyses exploratoires (EDA, visualisations)
â”œâ”€â”€ docker/                # Dockerfiles et configuration pour dÃ©ploiement
â”œâ”€â”€ .env                   # Fichier d'environnement
â”œâ”€â”€ requirements.txt       # DÃ©pendances du projet
â”œâ”€â”€ Dockerfile             # Image pour API ou Streamlit
â”œâ”€â”€ docker-compose.yml     # Orchestration du projet
â””â”€â”€ README.md              # Ce fichier
```

---

## âš™ï¸ Stack technique

- **Python 3.10+**
- **Pandas**, **Scikit-learn**, **XGBoost**
- **MLflow** pour le tracking
- **FastAPI** pour lâ€™API REST
- **Streamlit** pour lâ€™interface utilisateur
- **SQLite / PostgreSQL** avec **SQLAlchemy + Alembic**
- **Prefect** pour lâ€™orchestration des pipelines ETL
- **Docker** & **Docker Compose** pour la conteneurisation
- **Grafana** pour visualiser les mÃ©triques hardware et de consomation
- **Kuma** pour alerter en cas de crash de l'application
- **Loguru** pour le suivi des logs
- **Optuna** pour optimisation des hypers-paramÃ¨tres


---

## ğŸŒ Virtual environment

**Linux**
```batch
python3 -m venv .venv
source .venv/bin/activate
```

**MacOS-Windows**
```batch
python -m venv .venv
.venv\Scripts\activate
```

---

## ğŸš€ Lancement du projet

### 1. Cloner le dÃ©pÃ´t

```batch
git clone https://github.com/ThomasHtn/flight-delay-predictor.git
cd flight-delay-predictor
```

### 2. Lancer avec Docker

```batch
docker-compose up --build
```

Cela dÃ©marre :
- Lâ€™API FastAPI
- Lâ€™interface utilisateur Streamlit
- La base de donnÃ©es
- MLflow UI (sur `http://localhost:5000`)

### 3. AccÃ¨s aux services

- **API** : http://localhost:8000/docs
- **Interface Streamlit** : http://localhost:8501
- **MLflow UI** : http://localhost:5000

---

## Streamlit (front)
Depuis la racine du projet :
```batch
streamlit run app/main.py
```

---

## FastAPI (api)
Depuis la racine du projet :
```batch
uvicorn api.main:app --reload
```

---

## Monitoring (Grafana + prometheus)
Depuis le repertoire "monitoring" :
```batch
cd monitoring/
docker-compose up -d
```

Interface : 
Prometheus : http://localhost:9090
Grafana	http://localhost:3000

---

## âš—ï¸ Alembic

### CrÃ©er une nouvelle migration
Depuis la racine du projet :
```batch
alembic revision --autogenerate -m "nom de la migration"
```

### Appliquer la migration
Depuis la racine du projet :
```batch
alembic upgrade head
```

### Remplir la base de donnÃ©es
Depuis la racine du projet :
```batch
make populate-db
```
Cela va utiliser par dÃ©faut le fichier **"cleaned_data.csv"** pour remplir la base de donnÃ©es.

---

##  Mlflow

Lancer l'interface web

```batch
mlflow ui
``` 

Interface : http://localhost:5000